{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3fe70b-f381-4960-978b-49a7ae03b762",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m authenticate_API\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from utils import authenticate_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec32b65c-c8a8-45cd-94dd-e45c55079235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_response_for_posts(res):\n",
    "    \"\"\"\n",
    "    We use this function to convert responses to dataframes, in the context of POSTS extraction.\n",
    "    In this dataframe, we extract metrics from the json file given as a response\n",
    "    \n",
    "    Arg : res, which is the query we make to the Reddit API (a GET query).\n",
    "    Returns : a dataframe containing the info for each extracted post, that is (for now):\n",
    "    - subreddit: subreddit name;\n",
    "    - title: post title;\n",
    "    - selftext: post body;\n",
    "    - author_fullname: id of the post author (t2_'xxxxx');\n",
    "    - upvote_ratio; \n",
    "    - created_utc: publication time;\n",
    "    - num_comments;\n",
    "    - id: post ID, which is part of each post URL btw;\n",
    "    - kind: type prefix, for posts of a subreddit it is \"t3\", \"t1\" for a comment...\n",
    "    \"\"\"\n",
    "    # initialize temp dataframe for batch of data in response\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # loop through each post pulled from res and append to df\n",
    "    for post in res.json()['data']['children']:\n",
    "        df = df.append({\n",
    "            'subreddit': post['data']['subreddit'],\n",
    "            # Take the subreddit ID?\n",
    "            'title': post['data']['title'],\n",
    "            'selftext': post['data']['selftext'],\n",
    "            'author': post['data']['author'],\n",
    "            'upvote_ratio': post['data']['upvote_ratio'],\n",
    "            'created_utc': datetime.fromtimestamp(post['data']['created_utc']).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            'num_comments': post['data']['num_comments'],\n",
    "            'id': post['data']['id'],\n",
    "            'kind': post['kind']\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab5899d-a79b-401e-a58b-5a312f7d198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posts_extraction(subreddit:str=\"r/worldnews\"):\n",
    "    \"\"\"\n",
    "    Function to extract the first posts from a subreddit page.\n",
    "    \n",
    "    Args :\n",
    "    - subreddit: name of the subreddit under format \"r/name\", by default \"r/worldnews\";\n",
    "    - n_posts: int, number of posts we want to extract from the subreddit, by default 100.\n",
    "        A choice we make here is to automatically round this number to the upper hundred in our code.\n",
    "    Creates : a csv file containing the info about the extracted posts, that is:\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "\n",
    "    TODO: try-except, error prevention \n",
    "    \"\"\"\n",
    "\n",
    "    # We first authenticate to the API\n",
    "    headers = authenticate_API()\n",
    "\n",
    "    # initialize dataframe and parameters for pulling data in loop \n",
    "    data = pd.DataFrame()\n",
    "    params = {'limit': 100}\n",
    "\n",
    "    # Create a flag for scanning the subreddit as long as there is a post to fetch\n",
    "    flag = True\n",
    "\n",
    "    # At each loop, we extract 100 posts with their info\n",
    "    while flag:\n",
    "        # make request\n",
    "        res = requests.get(f\"https://oauth.reddit.com/{subreddit}\",\n",
    "                        headers=headers,\n",
    "                        params=params)\n",
    "\n",
    "        # get dataframe from response\n",
    "        new_df = df_from_response_for_posts(res)\n",
    "        # take the final row (oldest entry)\n",
    "        row = new_df.iloc[len(new_df)-1]\n",
    "        # create fullname\n",
    "        fullname = row['kind'] + '_' + row['id']\n",
    "        # add/update fullname in params\n",
    "        params['after'] = fullname\n",
    "        \n",
    "        # append new_df to data\n",
    "        data = data.append(new_df, ignore_index=True)\n",
    "\n",
    "        # Flag set to True if len(new_df)>=100, False otherwise\n",
    "        flag = (len(new_df)>=100)\n",
    "\n",
    "    # Save final dataframe to csv file, \n",
    "    # name_format: data_API_whole_\"subreddit name\"_\"date and hour\".csv\n",
    "    filename = f'dataAPI_whole_{subreddit.replace(\"/\",\"_\")}_'+ datetime.today().strftime('%Y-%m-%d_%H-%M') + \".csv\"\n",
    "\n",
    "    data.to_csv(filename, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5e9f5-f1cd-4601-96d6-b89fa6345e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}